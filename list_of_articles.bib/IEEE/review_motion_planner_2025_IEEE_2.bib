@INPROCEEDINGS{9739345,
  author={Stanley, Matthew and Tao, Lingfeng and Zhang, Xiaoli},
  booktitle={2021 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, 
  title={Robust Motion Mapping Between Human and Humanoids Using CycleAutoencoder}, 
  year={2021},
  volume={},
  number={},
  pages={93-98},
  abstract={Teleoperation needs accurate and robust motion mapping between human and humanoid motion to generate intuitive robot control with human-like motion. Data-driven methods are often deployed as it can result in intuitive, real time motion mapping. When using these methods, the common focus is on the accuracy of the motion mapping model. However, effort needs to be put into making the mapping model robust in face of noisy or incomplete dataset. In other words, the model needs to learn the generalizable mapping rules, not just be accurate in predicting the training data. To create a robust and accurate model for motion mapping, we developed the novel CycleAutoencoder method. This method simultaneously trains two autoencoders using traditional losses, mixed losses, and cycle losses. These losses allow the autoencoders to reconstruct the motion mutually between humans and humanoids. This allows the method to learn the mapping with improved accuracy and robustness compared to training a traditional autoencoder. The results of human subject involved experiments demonstrated that the CycleAutoencoder method can achieve both accuracy and robustness for the mapping compared with other autoencoder-based mapping methods.},
  keywords={Training;Robot control;Humanoid robots;Training data;Predictive models;Robustness;Real-time systems},
  doi={10.1109/ROBIO54168.2021.9739345},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7139282,
  author={Mainprice, Jim and Hayne, Rafi and Berenson, Dmitry},
  booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Predicting human reaching motion in collaborative tasks using Inverse Optimal Control and iterative re-planning}, 
  year={2015},
  volume={},
  number={},
  pages={885-892},
  abstract={To enable safe and efficient human-robot collaboration in shared workspaces, it is important for the robot to predict how a human will move when performing a task. While predicting human motion for tasks not known a priori is very challenging, we argue that single-arm reaching motions for known tasks in collaborative settings (which are especially relevant for manufacturing) are indeed predictable. Two hypotheses underlie our approach for predicting such motions: First, that the trajectory the human performs is optimal with respect to an unknown cost function, and second, that human adaptation to their partner's motion can be captured well through iterative replanning with the above cost function. The key to our approach is thus to learn a cost function which “explains” the motion of the human. To do this, we gather example trajectories from two participants performing a collaborative assembly task using motion capture. We then use Inverse Optimal Control to learn a cost function from these trajectories. Finally, we predict a human's motion for a given task by iteratively replanning a trajectory for a 23 DoF human kinematic model using the STOMP algorithm with the learned cost function in the presence of a moving collaborator. Our results suggest that our method outperforms baseline methods and generalizes well for tasks similar to those that were demonstrated.},
  keywords={Trajectory;Collaboration;Cost function;Planning;Optimal control;Prediction algorithms;Hidden Markov models},
  doi={10.1109/ICRA.2015.7139282},
  ISSN={1050-4729},
  month={May},}@ARTICLE{8606051,
  author={Ji, Chen and Kong, Minxiu and Li, Ruifeng},
  journal={IEEE Access}, 
  title={Time-Energy Optimal Trajectory Planning for Variable Stiffness Actuated Robot}, 
  year={2019},
  volume={7},
  number={},
  pages={14366-14377},
  abstract={A variable stiffness actuator is inspired by the human motor control and is the most popular actuator used to exploit the human performance and human-like motion. However, these actuators are typically highly non-linear and redundant not only in their kinematics but also in their dynamics due to their capability to modulate their stiffness and positions simultaneously. It is not trivial to generate the trajectory for a strongly non-linear and redundant dynamic system equipped with variable stiffness actuators. In this paper, a trajectory planning method for a variable stiffness actuated robot via a time-energy optimal control policy is proposed. The simulation studies demonstrate the effectiveness of the trajectory planning method through the case studies of a two degree of freedom variable stiffness actuated robot. Furthermore, the results show that the proposed method could be able to generate the motion which is similar to the human arm motion strategy.},
  keywords={Robots;Actuators;Trajectory;Planning;Optimal control;Task analysis;Dynamics;Optimal control method;redundant robot;variable stiffness actuator},
  doi={10.1109/ACCESS.2019.2891663},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9196742,
  author={Bushman, A. and Asselmeier, M. and Won, J. and LaViers, A.},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Toward Human-like Teleoperated Robot Motion: Performance and Perception of a Choreography-inspired Method in Static and Dynamic Tasks for Rapid Pose Selection of Articulated Robots}, 
  year={2020},
  volume={},
  number={},
  pages={10219-10225},
  abstract={In some applications, operators may want to create fluid, human-like motion on a remotely-operated robot, for example, a device used for remote telepresence. This paper examines two methods of controlling the pose of a Baxter robot via an Xbox One controller. The first method is a joint- by-joint (JBJ) method in which one joint of each limb is specified in sequence. The second method of control, named Robot Choreography Center (RCC), utilizes choreographic abstractions in order to simultaneously move multiple joints of the limb of the robot in a predictable manner. Thirty-eight users were asked to perform four tasks with each method. Success rate and duration of successfully completed tasks were used to analyze the performances of the participants. Analysis of the preferences of the users found that the joint-by-joint (JBJ) method was considered to be more precise, easier to use, safer, and more articulate, while the choreography-inspired (RCC) method of control was perceived as faster, more fluid, and more expressive. Moreover, performance data found that while both methods of control were over 80% successful for the two static tasks, the RCC method was an average of 11.85% more successful for the two more difficult, dynamic tasks. Future work will leverage this framework to investigate ideas of fluidity, expressivity, and human-likeness in robotic motion through online user studies with larger participant pools.},
  keywords={Task analysis;Training;Dynamics;Joints;Robot motion;Manipulators},
  doi={10.1109/ICRA40945.2020.9196742},
  ISSN={2577-087X},
  month={May},}@INPROCEEDINGS{9561180,
  author={Laux, Mario and Zell, Andreas},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Robot Arm Motion Planning Based on Geodesics}, 
  year={2021},
  volume={},
  number={},
  pages={7585-7591},
  abstract={Naturally, finding joint trajectories for robotic manipulators involves competing optimization goals. On the one hand, the end-effector should move along a predictable and short path while on the other hand joint movement and acceleration should be kept to a minimum. Obstacles in the workspace or joint limits complicate the situation even further. Constructing a metric that makes undesired configurations more expensive to travel through, we equip the joint space with a notion of cost. The motion planning task then reduces to the problem of finding cheapest paths connecting two configurations – so-called geodesics. We show how to construct suitable metrics for a variety of typical scenarios and present an efficient algorithm for the computation of the corresponding geodesics. Our approach makes it very easy to balance different optimization goals and produces natural and smooth manipulator movement.},
  keywords={Measurement;Costs;Conferences;End effectors;Planning;Trajectory;Space exploration},
  doi={10.1109/ICRA48506.2021.9561180},
  ISSN={2577-087X},
  month={May},}@INPROCEEDINGS{10342470,
  author={Noccaro, Alessia and Buscaglione, Silvia and Pinardi, Mattia and Di Pino, Giovanni and Formica, Domenico},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Evaluation of a 7-DoFs Robotic Manipulator as Haptic Interface During Planar Reaching Tasks}, 
  year={2023},
  volume={},
  number={},
  pages={5095-5100},
  abstract={In this work, we evaluated the suitability of using a 7 degrees of freedom robotic manipulator as a planar haptic interface for studies in motor neuroscience. In particular, we assessed to what extent it can measure human movement and forces without applying undesired perturbations. To this aim, we evaluated the amount of perturbation exerted by the robot during planar reaching movements when controlled to be as transparent as possible in the 2D task space, through an impedance control. Two planar specular configurations of the robot were tested, namely G1 and G2, which differ in the position of the “elbow joint” in the workspace. For both configurations, we estimated the inertial ellipsoids and simulated the forces for human-like forward movements. Performance was then experimentally assessed on 8 healthy participants, in 15 different positions in the workspace. The average handpath perturbation decreased and settled to 6 mm after 2 minutes of interaction. Interaction forces resulted specular for G1 and G2, with mean values below 5 N. Overall, the robotic manipulator resulted suitable for studies on planar reaching movements in both configurations, with a preference for the G1 configuration due to its symmetrical distribution of trajectory deviations, which anyway remain well below 1 cm for movements of 15 cm.},
  keywords={Neuroscience;Perturbation methods;Manipulators;Particle measurements;Haptic interfaces;Trajectory;Motion measurement},
  doi={10.1109/IROS55552.2023.10342470},
  ISSN={2153-0866},
  month={Oct},}@INPROCEEDINGS{10160965,
  author={Zhi, Weiming and Akinola, Iretiayo and Van Wyk, Karl and Ratliff, Nathan D. and Ramos, Fabio},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Global and Reactive Motion Generation with Geometric Fabric Command Sequences}, 
  year={2023},
  volume={},
  number={},
  pages={939-945},
  abstract={Motion generation seeks to produce safe and feasible robot motion from start to goal. Various tools at different levels of granularity have been developed. On one extreme, sampling-based motion planners focus on completeness - a solution, if it exists, would eventually be found. However, produced paths are often of low quality, and contain superfluous motion. On the other, reactive methods optimise the immediate cost to obtain the next controls, producing smooth and legible motion that can quickly adapt to perturbations, uncertainties, and changes in the environment. However, reactive methods are highly local, and often produce motion that become trapped in non-convex regions of the environment. This paper contributes, Geometric Fabric Command Sequences, a method that lies in the middle ground. It can produce globally optimal motion that is smooth and intuitive, while being also reactive. We model motion via a reactive Geometric Fabric policy that ingests a sequence of attractor states, or commands, and then apply global optimisation over the space of commands. We postulate that solutions for different problems and scenes are highly transferable when conditioned on environmental features. Therefore, an implicit generative model is trained on solutions from optimisation and environment features in a self-supervised manner. That is, faced with multiple motion generation problems, the learning and optimisation are contained within the same loop: the optimisation generates labels for learning, while the learning improves the optimisation for the next problem, which in turn provides higher quality labels. We empirically validate our method in both simulation and on a real-world 6-DOF JACO arm.},
  keywords={Uncertainty;Costs;Automation;Perturbation methods;Manipulators;Fabrics;6-DOF},
  doi={10.1109/ICRA48891.2023.10160965},
  ISSN={},
  month={May},}@INPROCEEDINGS{4755930,
  author={Albers, Albert and Ottnad, Jens and Sander, Christian},
  booktitle={Humanoids 2008 - 8th IEEE-RAS International Conference on Humanoid Robots}, 
  title={Development of a new wrist for the next generation of the humanoid robot ARMAR}, 
  year={2008},
  volume={},
  number={},
  pages={46-53},
  abstract={The development of a humanoid robot within the scope of the collaborative research centre 588 has the objective of creating a machine that can closely cooperate with humans. This development area presents new challenges for designers. In contrast to industrial robots - for which mechanical rigidity, precision and high velocities are primary requirements - the key aspects here are prevention of hazards to users, a motion space that corresponds to that of human beings, and a lightweight design. In order to meet these requirements, the robot must have humanlike appearance, motion space, and dexterity. Additionally, its kinematics should be familiar to the user, and its motions predictable, so as to encourage inexperienced persons to interact with the machine. This article gives insight into the design of a new wrist for the next generation of the humanoid robot ARMAR. The goals of the development project are both to improve the motion space and to achieve a humanlike appearance. The new mechanical design is described in detail completed by a study of a first prototype.},
  keywords={Wrist;Humanoid robots;Humans;Service robots;Orbital robotics;Collaboration;Aerospace industry;Hazards;Kinematics;Prototypes},
  doi={10.1109/ICHR.2008.4755930},
  ISSN={2164-0580},
  month={Dec},}@INPROCEEDINGS{8371080,
  author={Luo, Ren C. and Hsieh, Kai Chun},
  booktitle={2018 IEEE 15th International Workshop on Advanced Motion Control (AMC)}, 
  title={Tapping motion detection incorporate with impedance control of robotics tapotement massage on human tissue}, 
  year={2018},
  volume={},
  number={},
  pages={160-165},
  abstract={The objective of this paper is to realize a human-like massage tapping motion based on an anthropomorphic dual arm robot. The tapping motion is a unique technique in massage since it is much different from other massage techniques like kneading, stroking, acupressure and so on. The rate and rhythm are the most significant features which should be well-controlled in the tapping motion. To implement an effective robotic tapping motion, the on-line trajectory generator(OTG) is utilized to control the frequency during each tapping. Furthermore, since the massage is a human-contact motion, the safety of conducting a massage should be considered seriously. This paper uses the Cartesian based impedance control to enhance the safety and contact detection to satisfy diverse force demands during the robotic tapping motion. By these control methods, the feasibility of the tapping massage therapy based on robotic tapping motion is verified by the experiments. The experimental results demonstrate that the robotic tapping motion has reached 88 percentage similarity to the tapping motion of a massage therapist in different needed force. And the correlation coefficient is calculated to be about 0.95 which means there is a high positive relation between the robotic complete tapping motion and the human complete tapping motion.},
  keywords={Force;Manipulators;Robot sensing systems;Torque;Robot kinematics;Acceleration},
  doi={10.1109/AMC.2019.8371080},
  ISSN={1943-6580},
  month={March},}@INPROCEEDINGS{7989396,
  author={Wilbers, Daniel and Lioutikov, Rudolf and Peters, Jan},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Context-driven movement primitive adaptation}, 
  year={2017},
  volume={},
  number={},
  pages={3469-3475},
  abstract={Humanlike robot skills, e.g., cleaning a table or handing over a plate, can often be generalized to different task variations. Usually, these are start-/goal position, and trained environment changes. We investigate how to modify motion primitives to context changes, which are not included in the training data. Specifically, we focus on maintaining humanlike motion characteristics and generalizability, while adapting to unseen context. Therefore, we present an optimization technique, which maximizes the expected return and minimizes the Kullback-Leibler Divergence to the demonstrations at the same time. Simultaneously, our algorithm learns how to linearly combine the adapted primitive with the demonstrations, such that only relevant parts of the primitive are adapted. We evaluate our approach in obstacle avoidance and broken joint scenarios in simulation, as well as on a real robot.},
  keywords={Trajectory;Robots;Optimization;Shape;Mathematical model;Gaussian distribution;Standards},
  doi={10.1109/ICRA.2017.7989396},
  ISSN={},
  month={May},}@INPROCEEDINGS{4058405,
  author={Iossifidis, Ioannis and Schoner, Gregor},
  booktitle={2006 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Dynamical Systems Approach for the Autonomous Avoidance of Obstacles and Joint-limits for an Redundant Robot Arm}, 
  year={2006},
  volume={},
  number={},
  pages={580-585},
  abstract={We extend the attractor dynamics approach to generate goal-directed movement of a redundant, anthropomorphic arm while avoiding dynamic obstacles and respecting joint limits. To make the robot's movements human-like, we generate approximately straight-line trajectories by using two heading direction angles of the tool-point quite analogously to how movement is represented in the primate central nervous system. Two additional angles control the tool's spatial orientation so that it follows the tool-point's collision-free path. A fifth equation governs the redundancy angle, which controls the elevation of the elbow so as to avoid obstacles and respect joint limits. These variables make it possible to generate movement while sitting in an attractor (or, in the language of the potential field approach, in a minimum). We demonstrate the approach on an assistant robot, which interacts with human users in a shared workspace},
  keywords={Vehicle dynamics;Human robot interaction;Orbital robotics;Motion control;Impedance;Intelligent robots;Anthropomorphism;Equations;Speech analysis;Vehicles},
  doi={10.1109/IROS.2006.282468},
  ISSN={2153-0866},
  month={Oct},}@INPROCEEDINGS{5979654,
  author={Zanchettin, Andrea Maria and Rocco, Paolo and Bascetta, Luca and Symeonidis, Ioannis and Peldschus, Steffen},
  booktitle={2011 IEEE International Conference on Robotics and Automation}, 
  title={Kinematic analysis and synthesis of the human arm motion during a manipulation task}, 
  year={2011},
  volume={},
  number={},
  pages={2692-2697},
  abstract={Research in the field of human kinematic analysis has gained interest in recent years and has fostered new ideas and expectations. Next generation manipulators are expected to resemble a human-like behaviour at kinematic level, in order to avoid any unease or discomfort (like fear or shock) to the nearby humans. In this work, a kinematic experimental approach to study and synthesize the motion of the human arm is presented. In particular, the proposed scenario will be used to study how humans exploit the kinematic redundancy of their arms, for a future use in a robotic controller. A simple, yet accurate, method for human-like redundancy resolution in robotic manipulators is developed and verified.},
  keywords={Humans;Joints;Kinematics;Elbow;Redundancy;Correlation;Robots},
  doi={10.1109/ICRA.2011.5979654},
  ISSN={1050-4729},
  month={May},}@INPROCEEDINGS{8542505,
  author={Moon, A. Jung and Troniak, Daniel M. and Gleeson, Brian and Pan, Matthew K.X.J. and Zheng, Minhua and Blumer, Benjamin A. and MacLean, Karon and Crof, Elizabeth A.t},
  booktitle={2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)}, 
  title={Meet Me where I’m Gazing: How Shared Attention Gaze Affects Human-Robot Handover Timing}, 
  year={2014},
  volume={},
  number={},
  pages={334-341},
  abstract={In this paper we provide empirical evidence that using humanlike gaze cues during human-robot handovers can improve the timing and perceived quality of the handover event. Handovers serve as the foundation of many human-robot tasks. Fluent, legible handover interactions require appropriate nonverbal cues to signal handover intent, location and timing. Inspired by observations of human-human handovers, we implemented gaze behaviors on a PR2 humanoid robot. The robot handed over water bottles to a total of 102 naïve subjects while varying its gaze behaviour: no gaze, gaze designed to elicit shared attention at the handover location, and the shared attention gaze complemented with a turntaking cue. We compared subject perception of and reaction time to the robot-initiated handovers across the three gaze conditions. Results indicate that subjects reach for the offered object significantly earlier when a robot provides a shared attention gaze cue during a handover. We also observed a statistical trend of subjects preferring handovers with turn-taking gaze cues over the other conditions. Our work demonstrates that gaze can play a key role in improving user experience of human-robot handovers, and help make handovers fast and fluent.},
  keywords={Handover;Receivers;Robot kinematics;Trajectory;Timing;Human-Robot Communication;Handover;Head Gaze;Turntaking;Nonverbal Communication},
  doi={},
  ISSN={2167-2121},
  month={March},}@INPROCEEDINGS{9515565,
  author={Gulletta, Gianpaolo and Erlhagen, Wolfram and Bicho, Estela},
  booktitle={2021 IEEE International Conference on Development and Learning (ICDL)}, 
  title={Continual Learning of Human-like Arm Postures}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Inspired from established human motor control theories, our HUMP algorithm plans upper-limb collisions-free movements for anthropomorphic systems, which show kinematic human-like features [1]. Related cognitive issues can be further resolved when robots act as they are familiar with their workspace and can take initiative faster than in the early onsets of a task. Here, a continual learning technique is proposed to improve the performance of the HUMP under uncertainties of the items in a given scenario. Given the locality of the optimization-based HUMP algorithm, a meaningful initial guess, predicted from similar past motion experiences, can significantly reduce the computational cost and put the robot into action arguably faster than in the first attempts of planning with inexperienced initial guesses. This prediction is proposed to be incrementally refined by an optimal locally weighted regression method that operates on datasets of situational features that are regularly updated as new movements are planned by the robot in similar scenarios. The proposed cyclic experiential learner is tested on the selection of optimal human-like target postures in a reaching task with a large obstacle obstructing the straight-line path towards a given target. Results demonstrate the capability of extracting meaningful situational features in few sessions of online learning with a very limited size of the datasets. Comparisons with simple Euclidean locally weighted regression and random initializations showed the capability of planning target configurations of better quality with less computational cost. The proposed approach also exhibits to be robust against the interferences of new incoming samples depicting slightly changed situations of the same task.},
  keywords={Training;Motor drives;Uncertainty;Feature extraction;Prediction algorithms;Manipulators;Planning;developmental robotics;continual learning;cognitive robotics;human-like arm posture prediction;warm-starting IPOPT},
  doi={10.1109/ICDL49984.2021.9515565},
  ISSN={},
  month={Aug},}@ARTICLE{10583854,
  author={Mendez, Alberto and Prados, Adrian and Menendez, Elisabeth and Barber, Ramon},
  journal={IEEE Access}, 
  title={Everyday Objects Rearrangement in a Human-Like Manner via Robotic Imagination and Learning From Demonstration}, 
  year={2024},
  volume={12},
  number={},
  pages={92098-92119},
  abstract={The rearrangement of objects is an essential task in daily human life. Subconsciously, humans break down such tasks into three components: perception, reasoning, and execution, which are automatically resolved. This process represents a significant challenge for robots, as they must apply complex logic to treat all the information and successfully execute the task. In this research, we propose a solution to perform this task in a human-like manner. For that purpose, we developed a modular framework that provides the capability to observe and understand the scene, imagine the best solution and execute it, following human-like reasoning. This is done by combining a zero-shot deep learning model for perception, a zero-shot large diffusion model to provide an ordered and realistic final scene and a Learning from Demonstration algorithm for execution. To test the performance, we conducted several experiments to check the correct resolution of 2D rearrangement tasks. For that purpose, we have tested the feasibility of the final generated scene, the ability to generate the trajectory by means of human demonstrations and, finally, we have carried out experiments with two different robots in a simulated and a real environment. The results obtained prove the adaptability of our framework to different environments, objects and robots. Moreover, the success rate of solutions provided and the error in the position and orientation demonstrate a significant advance in the accuracy and effectiveness of solving rearrangement tasks.},
  keywords={Deep learning;Image segmentation;Accuracy;Diffusion models;Trajectory;Logic;Learning systems;Object segmentation;Robots;Cognition;Rearrangement task;robot perception;instance segmentation;diffusion model;prompt generation;learning from demonstration;imitation learning},
  doi={10.1109/ACCESS.2024.3422808},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9158797,
  author={Mizanoor Rahman, S. M.},
  booktitle={2020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)}, 
  title={A Method to Determine Human-Likeness in Social Motions of Anthropomorphic Robots}, 
  year={2020},
  volume={},
  number={},
  pages={1471-1476},
  abstract={The hand waving motion of a human was considered as a representative social motion because a human can use such motions for social interaction and communication. Twenty healthy human subjects were recruited to participate in a study, where each subject separately showed the hand waving motion at three different conditions: (i) both hands waved, (ii) only left hand waved, and (iii) only right hand waved. The hand waving motion was captured by a motion capture system for each subject in each condition separately. Then, the kinematics (absolute linear displacements, velocities and accelerations) along different axes at three different joints such as wrist, elbow and shoulder were analyzed. Then, the hand waving motion was generated in two different anthropomorphic robotic platforms where the robots were enabled to show their hand waving motions at the same three conditions. The kinematic features for hand waving of the robots along different axes at three different joints were captured using the motion capture system and analyzed in the same way as it was done for the humans. Then, a dynamic similarity metric called the Froude number was proposed and used to determine human-likeness in the form of dynamic equivalence between human and robot motions. Human-likeness between human and robot motions were also assessed through a human subject study to crosscheck the results obtained through the use of the Froude number. An agreement was found in the results obtained through two different methods (Froude number, subjective study). The proposed approach can help determine human-likeness of motions generated by anthropomorphic robots that can bring balance in human-like appearance and human-like motions or actions of anthropomorphic robots and virtual characters, which can enhance their chance of being accepted by their human counterparts for coexistence and collaboration.},
  keywords={Robot motion;Acceleration;Kinematics;Elbow;Dynamics;Wrist},
  doi={10.1109/AIM43001.2020.9158797},
  ISSN={2159-6255},
  month={July},}@INPROCEEDINGS{7353618,
  author={Lamperti, Cecilia and Zanchettin, Andrea Maria and Rocco, Paolo},
  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={A redundancy resolution method for an anthropomorphic dual-arm manipulator based on a musculoskeletal criterion}, 
  year={2015},
  volume={},
  number={},
  pages={1846-1851},
  abstract={In order to make humans feeling comfortable when working with robots, it is necessary for robots to be as much as possible “human-like” in both their appearance and movements. In redundant manipulators, it is possible to use the additional degrees of freedom in order to make the robot motion more human-like, thus increasing the quality of the human-robot interaction. In this work, a redundancy resolution method to address this issue is presented. Such a method considers the human musculoskeletal system and a biomechanical model of the human upper limbs in order to define a strategy to solve the redundancy for a dual-arm anthropomorphic manipulator as a human would do, then making the robot able to both perform the prescribed task and to assume human-like postures.},
  keywords={Redundancy;Manipulators;Wrist;Muscles;Biomechanics;Shoulder},
  doi={10.1109/IROS.2015.7353618},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8460774,
  author={Bazzi, Salah and Ebert, Julia and Hogan, Neville and Sternad, Dagmar},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Stability and Predictability in Dynamically Complex Physical Interactions}, 
  year={2018},
  volume={},
  number={},
  pages={5540-5545},
  abstract={This study examines human control of physical interaction with objects that exhibit complex (nonlinear, chaotic, underactuated) dynamics. We hypothesized that humans exploited stability properties of the human-object interaction. Using a simplified 2D model for carrying a “cup of coffee”, we developed a virtual implementation to identify human control strategies. Transporting a cup of coffee was modeled as a cart with a suspended pendulum, where humans moved the cart on a horizontal line via a robotic manipulandum. The specific task was to transport the cart-pendulum system to a target, as fast as possible, while accommodating assistive and resistive perturbations. To assess trajectory stability, we applied contraction analysis. We showed that when the perturbation was assistive, humans absorbed the perturbation by controlling cart trajectories into a contraction region prior to the perturbation. When the perturbation was resistive, subjects passed through a contraction region following the perturbation. Entering a contraction region stabilizes performance and makes the dynamics more predictable. This human control strategy could inspire more robust control strategies for physical interaction in robots.},
  keywords={Perturbation methods;Task analysis;Trajectory;Robots;Mathematical model;Stability analysis;Jacobian matrices},
  doi={10.1109/ICRA.2018.8460774},
  ISSN={2577-087X},
  month={May},}@INPROCEEDINGS{6225090,
  author={Kizaki, Takahiro and Namiki, Akio},
  booktitle={2012 IEEE International Conference on Robotics and Automation}, 
  title={Two ball juggling with high-speed hand-arm and high-speed vision system}, 
  year={2012},
  volume={},
  number={},
  pages={1372-1377},
  abstract={Humans can perform fast and skillful manipulations using various parts of the body by effectively utilizing the dynamics of the targets. Visual sensation is the most important human sense used for such manipulations. Juggling is one such example involving skillful and dynamic manipulations, and visual information is essential for it to be successful. Previously, there have been several studies about robotic juggling. However, none of these studies have considered cases in which a human-like multifingered hand-arm is used for the robotic juggling. The purpose of this study is to achieve two-ball juggling using our robotic hand-arm, which has three general purpose fingers, and stereo vision. Image processing is executed at 500 fps using a high-speed vision system and graphics processing unit (GPU). The trajectory of the robotic hand-arm is generated based on the ball's estimated dropping position and moment, and the robot catches the ball. The juggling motion is achieved by repeating this cycle. Therefore, the results show that the robot successfully juggles two balls using our hand-arm system.},
  keywords={Joints;Trajectory;End effectors;Cameras;Humans;Feature extraction},
  doi={10.1109/ICRA.2012.6225090},
  ISSN={1050-4729},
  month={May},}@INPROCEEDINGS{6530874,
  author={Ding, Ming and Ikeura, Ryojun and Mukai, Toshiharu and Nagashima, Hiromichi and Hirano, Shinya and Matsuo, Kazuya and Sun, Minghui and Jiang, Chang'an and Hosoe, Shigeyuki},
  booktitle={2012 First International Conference on Innovative Engineering Systems}, 
  title={Comfort estimation during lift-up using nursing-care robot — RIBA}, 
  year={2012},
  volume={},
  number={},
  pages={225-230},
  abstract={In our research center, we have developed a nursing-care assistant robot - RIBA, which can lift up and transfer person between bed and wheelchair using its two human like arms. In this research, we develop a new method to estimate the comfortable feeling of human, which can help our robot - RIBA to find the best lifting-up motion automatically. By using a lifting-up model and optimizing a weighted evaluation function, we can calculate the lifting forces and the human joint torques during the lift-up. A weighted evaluation is used to reflect the change of comfortable feeling. We also carried out some experiments to check the model and the estimating method. During the lift-up, we measured subjects' EMG signal. And after the lift-up, questionnaires survey is conducted. The change trends between estimated and measured value show the effectiveness of the model and the method quantitatively and qualitatively.},
  keywords={},
  doi={10.1109/ICIES.2012.6530874},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{5354357,
  author={Yang, Woosung and Bae, Ji-Hun and Oh, Yonghwan and Chong, Nak Young and You, Bum Jae},
  booktitle={2009 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Biologically inspired control for robotic arm using neural oscillator network}, 
  year={2009},
  volume={},
  number={},
  pages={135-141},
  abstract={It is known that biologically inspired neural systems could exhibit natural dynamics efficiently and robustly for motion control, especially for rhythmic motion tasks. In addition, humans or animals exhibit natural adaptive motions without considering their kinematic configurations against unexpected disturbances or environment changes. In this paper, we focus on rhythmic arm motions that can be achieved by using a controller based on neural oscillators and virtual force. In comparison with conventional researches, this work treats neither trajectories planning nor inverse kinematics. Instead of those, a few desired points in task-space and a control method with Jacobian transpose and joint velocity damping are merely adopted. In addition, if the joints of robotic arms are coupled to neural oscillators, they may be capable of achieving biologically inspired motions corresponding to environmental changes. To verify the proposed control scheme, we perform some simulations to trace a desired motion and show the potential features related with self-adaptation that enables a three-link planar arm to make adaptive changes from the given motion to a compliant motion. Specifically, we investigate that human-like movements and motion repeatability are satisfied under kinematic redundancy of joints.},
  keywords={Robot control;Biological control systems;Oscillators;Motion control;Kinematics;Robust control;Humans;Animals;Force control;Trajectory},
  doi={10.1109/IROS.2009.5354357},
  ISSN={2153-0866},
  month={Oct},}@INPROCEEDINGS{6005283,
  author={Surdilovic, D. and Nguyen, T-M. and Radojicic, J.},
  booktitle={2011 RO-MAN}, 
  title={Human-like variable-impedance control for life-cycle testing}, 
  year={2011},
  volume={},
  number={},
  pages={150-155},
  abstract={The paper presents robotic approach to life-cycle testing based on advanced compliance control algorithms. This strategy has been demonstrated as meaningful testing approach considering repeatability and reproducibility. Moreover, developed testing procedures mimic human motion and ensure human-like testing conditions. That is a crucial advantage over simple testing machines or convenient industrial robots, which can not realize comparable system behavior. Application of a variable-impedance control strategy provides a feasible approach in reproducing human behavior and realizing faster life-cycle test execution.},
  keywords={Impedance;Service robots;Force;Humans;Testing;Damping},
  doi={10.1109/ROMAN.2011.6005283},
  ISSN={1944-9437},
  month={July},}@INPROCEEDINGS{7989197,
  author={Shu, Tianmin and Gao, Xiaofeng and Ryoo, Michael S. and Zhu, Song-Chun},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Learning social affordance grammar from videos: Transferring human interactions to human-robot interactions}, 
  year={2017},
  volume={},
  number={},
  pages={1669-1676},
  abstract={In this paper, we present a general framework for learning social affordance grammar as a spatiotemporal AND-OR graph (ST-AOG) from RGB-D videos of human interactions, and transfer the grammar to humanoids to enable a real-time motion inference for human-robot interaction (HRI). Based on Gibbs sampling, our weakly supervised grammar learning can automatically construct a hierarchical representation of an interaction with long-term joint sub-tasks of both agents and short term atomic actions of individual agents. Based on a new RGB-D video dataset with rich instances of human interactions, our experiments of Baxter simulation, human evaluation, and real Baxter test demonstrate that the model learned from limited training data successfully generates human-like behaviors in unseen scenarios and outperforms both baselines.},
  keywords={Grammar;Robots;Videos;Human-robot interaction;Spatiotemporal phenomena;Grounding;Real-time systems},
  doi={10.1109/ICRA.2017.7989197},
  ISSN={},
  month={May},}@INPROCEEDINGS{5650305,
  author={Mülling, Katharina and Kober, Jens and Peters, Jan},
  booktitle={2010 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={A biomimetic approach to robot table tennis}, 
  year={2010},
  volume={},
  number={},
  pages={1921-1926},
  abstract={Although human beings see and move slower than table tennis or baseball robots, they manage to outperform such robot systems. One important aspect of this better performance is the human movement generation. In this paper, we study trajectory generation for table tennis from a biomimetic point of view. Our focus lies on generating efficient stroke movements capable of mastering variations in the environmental conditions, such as changing ball speed, spin and position. We study table tennis from a human motor control point of view. To make headway towards this goal, we construct a trajectory generator for a single stroke using the discrete movement stages hypothesis and the virtual hitting point hypothesis to create a model that produces a human-like stroke movement. We verify the functionality of the trajectory generator for a single forehand stroke both in a simulation and using a real Barrett WAM™.},
  keywords={Trajectory;Joints;Computational modeling;Acceleration;Humans;Robot kinematics},
  doi={10.1109/IROS.2010.5650305},
  ISSN={2153-0866},
  month={Oct},}@INPROCEEDINGS{8700365,
  author={Kiyokawa, Takuya and Ding, Ming and Ricardez, Gustavo Alfonso Garcia and Takamatsu, Jun and Ogasawara, Tsukasa},
  booktitle={2019 IEEE/SICE International Symposium on System Integration (SII)}, 
  title={Generation of a Tactile-based Pouring Motion Using Fingertip Force Sensors}, 
  year={2019},
  volume={},
  number={},
  pages={669-674},
  abstract={To pour various contents from a container, a robot needs to be able to generate a trajectory of its arm, to grasp containers, and to estimate the amount poured. We propose a method only based on tactile sensing to generate the overall pouring motion including all the required abilities. Using a robot arm, we generated a human-like tipping motion and developed a grasping strategy to prevent slippage of the robot's fingertips for objects whose center of gravity changes while pouring. With this method, the robot uses the fingertip forces to estimate the amount poured independently of the material being poured and the working environment of the robot. By using a tactile-based pouring motion rather than a vision-based pouring motion, we expect the robot to achieve a general-purpose, robust, and highly accurate pouring motion. We evaluated the usefulness of the proposed tactile-based pouring motion through pouring experiments where the robot poured the contents from a plastic bottle into a cup. The robot pours the three types of materials with different particle sizes from a plastic bottle into a cup. The results showed that the proposed method enabled the robot to pour the contents into the cup while estimating the mass of the poured material with an error less than 17 grams.},
  keywords={Robot sensing systems;Containers;Grasping;Trajectory;Gravity},
  doi={10.1109/SII.2019.8700365},
  ISSN={2474-2325},
  month={Jan},}@INPROCEEDINGS{6630722,
  author={Namiki, Akio and Matsushita, Sakyo and Ozeki, Takahiro and Nonami, Kenzo},
  booktitle={2013 IEEE International Conference on Robotics and Automation}, 
  title={Hierarchical processing architecture for an air-hockey robot system}, 
  year={2013},
  volume={},
  number={},
  pages={1187-1192},
  abstract={In this study, we design a novel air-hockey robot system that switches strategies according to the playing styles of its opponent. The system consists of a four-axis robot arm and two high-speed vision sensors. We control the robot using visual information received at a rate of 500Hz. The control system consists of three layers: motion control, short-term strategy, and long-term strategy. In the motion control layer, the robot is controlled by visual information of the puck. In the short-term strategy layer, motion of the robot is changed according to the motion characteristics of the puck. In the long-term strategy layer, the motion of the robot is changed according to the playing style of the opponent. By integrating the three control layers, the robot exhibits human-like reactions, which increase the appeal of the game. Experimental results verify the effectiveness of our proposed method.},
  keywords={Robots;Games;Histograms;Trajectory;Switches;Vectors},
  doi={10.1109/ICRA.2013.6630722},
  ISSN={1050-4729},
  month={May},}@ARTICLE{10486907,
  author={Kong, Fanyi and Zambella, Grazia and Monteleone, Simone and Grioli, Giorgio and G. Catalano, Manuel and Bicchi, Antonio},
  journal={IEEE Access}, 
  title={A Suspended Aerial Manipulation Avatar for Physical Interaction in Unstructured Environments}, 
  year={2024},
  volume={12},
  number={},
  pages={48108-48125},
  abstract={This paper presents an aerial platform capable of performing physically interactive tasks in unstructured environments with human-like dexterity under human supervision. This aerial platform consists of a humanoid torso attached to a hexacopter. A two-degree-of-freedom head and two five-degree-of-freedom arms equipped with SoftHands provide the requisite dexterity to allow human operators to carry out various tasks. A robust tendon-driven structure is purposefully designed for the arms, considerably reducing the impact of arm inertia on the aerial base in motion. In addition, tendons provide flexibility to the joints, which enhances the robustness of the arm preventing damage in interaction with the environment. To increase the payload of the aerial system and the battery life, we use the concept of Suspended Aerial Manipulation, i.e., the flying humanoid can be connected with a tether to a structure, e.g., a building, a fixed bracket, a supporting crane, or a larger airborne carrier. Importantly, to maximize portability and applicability, we adopt a modular approach exploiting commercial components for the aerial base hardware and autopilot. We develop an outer stabilizing control loop to maintain the attitude, compensating for the tether force and for the humanoid head and arm motions. The humanoid can be controlled by a remote operator, thus effectively realizing a Suspended Aerial Manipulation Avatar. The proposed system is validated through experiments in indoor scenarios reproducing post-disaster tasks.},
  keywords={Manipulators;Arms;Robots;Avatars;Grippers;Autonomous aerial vehicles;Task analysis;Aerial manipulation;dual-arm robot;teleoperated avatar;cable-suspended robot},
  doi={10.1109/ACCESS.2024.3383774},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10375220,
  author={Ribayashi, Yoshimoto and Miyama, Kazuhiro and Miki, Akihiro and Kawaharazuka, Kento and Okada, Kei and Kawasaki, Koji and Inaba, Masayuki},
  booktitle={2023 IEEE-RAS 22nd International Conference on Humanoid Robots (Humanoids)}, 
  title={Development of a Wire-Wound Muscle-Tendon Complex Drive and Its Application to a Two-Dimensional Robot Configuration}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Muscle-tendon complexes that fill the body may also fill the gap between robots and humans. Several wire-driven humanoids have been developed, and their advantage is that they are soft and easily adaptable to the environment. However, wires are difficult to handle, and contact with the environment by wire parts causes malfunctions. In addition, the robot should look more human-like in order to coexist with humans. In this study, we approach these problems by proposing a driving method called wire-wound Muscle Tendon Complex (ww-MTC), which incorporates muscle expansion into the wire drive. We have realized the concept in a two-dimensional geometry and developed a 1-axis 3-muscle test robot with ww-MTC. The test robot was confirmed to suppress wire loosening, interference, and abrasion. It was also confirmed that the entire body can be in contact with the environment, and giving the robot a muscular appearance.},
  keywords={Actuators;Deformation;Wires;Force;Time series analysis;Humanoid robots;Muscles},
  doi={10.1109/Humanoids57100.2023.10375220},
  ISSN={2164-0580},
  month={Dec},}@INPROCEEDINGS{6265962,
  author={Maeba, Tomohide and Minami, Mamoru and Yanou, Akira and Matsuno, Takayuki and Nishiguchi, Jumpei},
  booktitle={2012 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)}, 
  title={Dynamical analyses of humanoid's walking by visual lifting stabilization based on event-driven state transition}, 
  year={2012},
  volume={},
  number={},
  pages={7-14},
  abstract={Biped locomotion created by a controller based on Zero-Moment Point [ZMP] known as reliable control method looks different from human's walking on the view point that ZMP-based walking does not include falling state. However, the walking control that does not depend on ZMP is vulnerable to turnover. Therefore, keeping the event-driven walking of dynamical motion stable is important issue for realization of human-like natural walking. In this paper, walking model of humanoid including slipping, bumping, surface-contacting and point-contacting of foot is discussed, and its dynamical equation is derived by Newton-Euler method. Then, we propose walking stabilizer named “Visual Lifting Stabilization” strategy to enhance standing robustness and prevent the robot from falling down. Simulation results indicate that this strategy helps stabilize pose and bipedal walking even though ZMP is not kept inside convex hull of supporting area.},
  keywords={Legged locomotion;Foot;Mathematical model;Equations;Torque;Joints},
  doi={10.1109/AIM.2012.6265962},
  ISSN={2159-6255},
  month={July},}@INPROCEEDINGS{6225120,
  author={Parker, Chris A. C. and Croft, Elizabeth A.},
  booktitle={2012 IEEE International Conference on Robotics and Automation}, 
  title={Design & Personalization of a Cooperative Carrying Robot Controller}, 
  year={2012},
  volume={},
  number={},
  pages={3916-3921},
  abstract={In the near future, as robots become more advanced and affordable, we can envision their use as intelligent assistants in a variety of domains. An exemplar human-robot task identified in many previous works is cooperatively carrying a physically large object. An important task objective is to keep the carried object level. In this work, we propose an admittance-based controller that maintains a level orientation of a cooperatively carried object. The controller raises or lowers its end of the object with a human-like behavior in response to perturbations in the height of the other end of the object (e.g., the end supported by the human user). We also propose a novel tuning procedure, and find that most users are in close agreement about preferring a slightly under-damped controller response, even though they vary in their preferences regarding the speed of the controller's response.},
  keywords={Humans;Tuning;Force;Trajectory;Robot sensing systems;Damping},
  doi={10.1109/ICRA.2012.6225120},
  ISSN={1050-4729},
  month={May},}@INPROCEEDINGS{8870958,
  author={Sorour, Mohamed and Cherubini, Andrea and Fraisse, Philippe},
  booktitle={2019 European Conference on Mobile Robots (ECMR)}, 
  title={Motion Control for Steerable Wheeled Mobile Manipulation}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={In this paper, we address the problem of long travel mobile manipulation for steerable wheeled mobile robots (SWMR) operating in human shared environment. On one hand, a small footprint is required while maintaining a fixed arm configuration, to make robot motion predictable for near individuals during the long traverse. On the other hand, redundancy resolution poses a challenge since there is no direct kinematic mapping between the task and joint spaces for SWMR. Hence, we propose a redundancy resolution algorithm that enables switching between 3 modes of operation based on the Euclidean norm of the motion task error. In particular, we employ a floating base model for the mobile platform, and enhance the end effector motion performance by predicting the error between such model and the actual (SWMR) one. Such error is then compensated using the highly responsive arm manipulator. The proposed methodology is successfully validated in simulations on a Neobotix-MPO700 SWMR with a Kuka LWR-IV manipulator mounted on it.},
  keywords={Task analysis;Manipulators;Mobile robots;Jacobian matrices;Redundancy;Kinematics;Motion control;mobile manipulation;pseudo-omni mobile robot;steerable mobile robot;long travel manipulation},
  doi={10.1109/ECMR.2019.8870958},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9739425,
  author={Zhao, Liang and Yu, Peng and Yang, Tie and Yang, Yang and Xi, Ning and Liu, Lianqing},
  booktitle={2021 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, 
  title={A Learning from Demonstration Method for Generating Human-like Actions on Redundant Manipulators}, 
  year={2021},
  volume={},
  number={},
  pages={913-918},
  abstract={Achieving human-like actions on robots can significantly improve the quality of human-robot collaboration (HRC). However, it is not easy to control the general-purpose robotic manipulators to work in a human-like style when the kinematic discrepancy exists between humans and robots. In this paper, we propose a human-in-the-loop learning framework to enable human-like properties on a general-purpose redundant manipulator. We collect the human-like demonstration dataset via teleoperation. We then use the behavioral cloning method to train a neural network policy to generate human-like constraints for the redundant manipulator automatically. Furthermore, we introduce an online relabeling method to accelerate learning and relieve workload in the demonstration. Experimental results showed that our proposed framework could successfully train a human-like constraint generation policy with a demonstration dataset collected within a few minutes. Appearance similarity could be seen between the human arm posture and the configuration of the manipulator when performing pose tracking tasks.},
  keywords={Conferences;Neural networks;Education;Cloning;Kinematics;Filtering algorithms;Manipulators},
  doi={10.1109/ROBIO54168.2021.9739425},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{5651377,
  author={Yang, Woosung and Bae, Ji-Hun and Oh, Yonghwan and Chong, Nak Young and You, Bum-Jae and Oh, Sang-Rok},
  booktitle={2010 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={CPG based self-adapting multi-DOF robotic arm control}, 
  year={2010},
  volume={},
  number={},
  pages={4236-4243},
  abstract={Recently, biologically inspired control approaches for robotic systems that involve the use of central pattern generators (CPGs) have been attracting considerable attention owing to the fact that most humans or animals move and walk easily without explicitly controlling their movements. Furthermore, they exhibit natural adaptive motions against unexpected disturbances or environmental changes without considering their kinematic configurations. Inspired by such novel phenomena, this paper endeavors to achieve self-adapting robotic arm motion. For this, biologically inspired CPG based control is proposed. In particular, this approach deals with crucial problems such as motion generation and repeatability of the joints emerged remarkably in most of redundant DOF systems. These problems can be overcome by employing a control based on artificial neural oscillators, virtual force and virtual muscle damping instead of trajectories planning and inverse kinematics. Biologically inspired motions can be attained if the joints of a robotic arm are coupled to neural oscillators and virtual muscles. We experimentally demonstrate self-adaptation motions that that enables a 7-DOF robotic arm to make adaptive changes from the given motion to a compliant motion. In addition, it is verified with real a real robotic arm that human-like movements and motion repeatability are satisfied under kinematic redundancy of joints.},
  keywords={Oscillators;Joints;Neurons;Eigenvalues and eigenfunctions;Robot sensing systems},
  doi={10.1109/IROS.2010.5651377},
  ISSN={2153-0866},
  month={Oct},}@ARTICLE{9541299,
  author={Cong, Yang and Chen, Ronghan and Ma, Bingtao and Liu, Hongsen and Hou, Dongdong and Yang, Chenguang},
  journal={IEEE Transactions on Cybernetics}, 
  title={A Comprehensive Study of 3-D Vision-Based Robot Manipulation}, 
  year={2023},
  volume={53},
  number={3},
  pages={1682-1698},
  abstract={Robot manipulation, for example, pick-and-place manipulation, is broadly used for intelligent manufacturing with industrial robots, ocean engineering with underwater robots, service robots, or even healthcare with medical robots. Most traditional robot manipulations adopt 2-D vision systems with plane hypotheses and can only generate 3-DOF (degrees of freedom) pose accordingly. To mimic human intelligence and endow the robot with more flexible working capabilities, 3-D vision-based robot manipulation has been studied. However, this task is still challenging in the open world especially for general object recognition and pose estimation with occlusion in cluttered backgrounds and human-like flexible manipulation. In this article, we propose a comprehensive analysis of recent progress about the 3-D vision for robot manipulation, including 3-D data acquisition and representation, robot-vision calibration, 3-D object detection/recognition, 6-DOF pose estimation, grasping estimation, and motion planning. We then present some public datasets, evaluation criteria, comparisons, and challenges. Finally, the related application domains of robot manipulation are given, and some future directions and open problems are studied as well.},
  keywords={Robots;Service robots;Grasping;Data acquisition;Pose estimation;Force;Cameras;3-D object recognition;grasping estimation;motion planning;pose estimation;robot manipulation},
  doi={10.1109/TCYB.2021.3108165},
  ISSN={2168-2275},
  month={March},}@INPROCEEDINGS{10611106,
  author={Lu, Kai and Zhong, Jia-Xing and Yang, Bo and Wang, Bing and Markham, Andrew},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Learning to Catch Reactive Objects with a Behavior Predictor}, 
  year={2024},
  volume={},
  number={},
  pages={9205-9211},
  abstract={Tracking and catching moving objects is an important ability for robots in a dynamic world. Whilst some objects have highly predictable state evolution e.g., the ballistic trajectory of a tennis ball, reactive targets alter their behavior in response to motion of the manipulator. Reactive applications range from gently capturing living animals such as snakes or fish for biological investigations, to smoothly interacting with and assisting a person. Existing works for dynamic catching usually perform target prediction followed by planning, but seldom account for highly non-linear reactive behaviors. Alternatively, Reinforcement Learning (RL) based methods simply treat the target and its motion as part of the observation of the world-state, but perform poorly due to the weak reward signal. In this work, we blend the approach of an explicit, yet learned, target state predictor with RL. We further show how a tightly coupled predictor which ‘observes’ the state of the robot leads to significantly improved anticipatory action, especially with targets that seek to evade the robot following a simple policy. Experiments show that our method achieves an 86.4% (open plane area) and a 73.8% (room) success rate on evasive objects, outperforming monolithic reinforcement learning and other techniques. We also demonstrate the efficacy of our approach across varied targets and trajectories. All code, data, and additional videos are at this GitHub link: https://kl-research.github.io/dyncatch.},
  keywords={Target tracking;Sports equipment;Dynamics;Reinforcement learning;Trajectory;Planning;Task analysis},
  doi={10.1109/ICRA57147.2024.10611106},
  ISSN={},
  month={May},}@ARTICLE{10198302,
  author={Solak, Gokhan and Jamone, Lorenzo},
  journal={IEEE Transactions on Haptics}, 
  title={Haptic Exploration of Unknown Objects for Robust In-Hand Manipulation}, 
  year={2023},
  volume={16},
  number={3},
  pages={400-411},
  abstract={Human-like robot hands provide the flexibility to manipulate a variety of objects that are found in unstructured environments. Knowledge of object properties and motion trajectory is required, but often not available in real-world manipulation tasks. Although it is possible to grasp and manipulate unknown objects, an uninformed grasp leads to inferior stability, accuracy, and repeatability of the manipulation. Therefore, a central challenge of in-hand manipulation in unstructured environments is to acquire this information safely and efficiently. We propose an in-hand manipulation framework that does not assume any prior information about the object and the motion, but instead extracts the object properties through a novel haptic exploration procedure and learns the motion from demonstration using dynamical movement primitives. We evaluate our approach by unknown object manipulation experiments using a human-like robot hand. The results show that haptic exploration improves the manipulation robustness and accuracy significantly, compared to the virtual spring framework baseline method that is widely used for grasping unknown objects.},
  keywords={Friction;Robot sensing systems;Robots;Task analysis;Shape;Grasping;Springs;Haptic exploration;dexterous manipulation;grasping force optimisation;learning from demonstration},
  doi={10.1109/TOH.2023.3300439},
  ISSN={2329-4051},
  month={July},}@INPROCEEDINGS{10569519,
  author={Kodandaramu, Laasya and Srikantan, Maalavika and Sanoj, Jacob V and Narayan, Kaushik and Tripathi, Shikha},
  booktitle={2024 10th International Conference on Control, Automation and Robotics (ICCAR)}, 
  title={Dynamic Obstacle Avoidance in Cobots with Multiple Random Moving Obstacles}, 
  year={2024},
  volume={},
  number={},
  pages={122-127},
  abstract={Traditional industrial robots are generally massive, heavy, and dangerous and are therefore generally isolated from humans. Collaborative robots or COBOTs are designed to collaborate and work with humans in a shared workspace. These are typically smaller and lighter than traditional industrial robots and are therefore more flexible and easier to deploy in a variety of settings. One of the most crucial problems that need to be addressed for cobots is Dynamic Obstacle Avoidance as they will be working in an environment where there will be constant human movement. This paper presents an efficient solution to this problem employing a Non-Linear Model Predictive Controller (NMPC) for realtime path planning. It has been used to obtain the most optimum trajectory while avoiding dynamic obstacles. The KINOVA Gen3 manipulator has been simulated with static and dynamic obstacle modelling. The NMPC controls the arm to minimize differences between the system's current state and the desired goal position while avoiding obstacles. A detailed visualization of the system motion has also been included. The work has been tested and the results have been shown for 4 different cases - reference case with no obstacles, case 1 with three obstacles, case 2 with four obstacles and case 3 with a simulated human-like obstacle to mimic a typical cobot scenario. Detailed error analysis including end-effector and implementation errors has also been shown for each of the 4 cases and is promising.},
  keywords={Visualization;Automation;Error analysis;Dynamics;Predictive models;Industrial robots;End effectors;Cobots;Nonlinear Model Predictive Control;Manipulator;MATLAB;Kinova Gen3;dynamic obstacles},
  doi={10.1109/ICCAR61844.2024.10569519},
  ISSN={2251-2454},
  month={April},}@ARTICLE{8424874,
  author={Oguz, Ozgur S. and Pfirrmann, Ben M. and Guo, Mingpan and Wollherr, Dirk},
  journal={IEEE Robotics and Automation Letters}, 
  title={Learning Hand Movement Interaction Control Using RNNs: From HHI to HRI}, 
  year={2018},
  volume={3},
  number={4},
  pages={4100-4107},
  abstract={A key problem in robotics is enabling an autonomous agent to perform human-like arm movements in close proximity to another human. However, modeling the human decision and control process of the movement during dyadic interaction presents a challenge. Although, most prior approaches rely on multicomponent robot motion planning architectures, we use data of two humans performing interfering arm reaching movements to extract and transfer interaction behavior control skill to a robotic agent. A recurrent neural network-based framework is constructed to learn a policy that computes control signals for a robot end effector in order to replace one human. The learned policy is benchmarked against unseen interaction data and a state-of-the-art learning from demonstration framework in simulated scenarios. We compare several architectures and investigate a new activation function of three stacked tanh(). The results show that the proposed framework successfully learns a policy to imitate human movement behavior control during dyadic interaction. The policy is transferred to a real robot and its feasibility for close-proximity human-robot interaction is shown.},
  keywords={Recurrent neural networks;Task analysis;Manipulators;Computer architecture;Hidden Markov models;Convergence;Human-robot interaction;human-in-the-loop;learning from demonstration;recurrent neural networks},
  doi={10.1109/LRA.2018.2862923},
  ISSN={2377-3766},
  month={Oct},}@INPROCEEDINGS{6225008,
  author={Cohen, Benjamin and Chitta, Sachin and Likhachev, Maxim},
  booktitle={2012 IEEE International Conference on Robotics and Automation}, 
  title={Search-based planning for dual-arm manipulation with upright orientation constraints}, 
  year={2012},
  volume={},
  number={},
  pages={3784-3790},
  abstract={Dual-arm manipulation is an increasingly important skill for robots operating in home, retail and industrial environments. Dual-arm manipulation is especially essential for tasks involving large objects which are harder to grasp and manipulate using a single arm. In this work, we address dual-arm manipulation of objects in indoor environments. We are particularly focused on tasks that involve an upright orientation constraint on the grasped object. Such constraints are often present in human environments, e.g. when manipulating a tray of food or a container with fluids. In this paper, we present a search-based approach that is capable of planning dual-arm motions, often within one second, in cluttered environments while adhering to the orientation constraints. Our approach systematically constructs a graph in task space and generates motions that are consistent across runs with similar start/goal configurations and are low-cost. These motions come with guarantees on completeness and bounds on the suboptimality with respect to the graph that encodes the planning problem. For many problems, the consistency of the generated motions is important as it helps make the actions of the robot more predictable for a human interacting with the robot.},
  keywords={Joints;Planning;Robots;Search problems;Kinematics;Humans;Glass},
  doi={10.1109/ICRA.2012.6225008},
  ISSN={1050-4729},
  month={May},}@INPROCEEDINGS{5650851,
  author={Pattacini, Ugo and Nori, Francesco and Natale, Lorenzo and Metta, Giorgio and Sandini, Giulio},
  booktitle={2010 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={An experimental evaluation of a novel minimum-jerk cartesian controller for humanoid robots}, 
  year={2010},
  volume={},
  number={},
  pages={1668-1674},
  abstract={In this paper we describe the design of a Cartesian Controller for a generic robot manipulator. We address some of the challenges that are typically encountered in the field of humanoid robotics. The solution we propose deals with a large number of degrees of freedom, produce smooth, human-like motion and is able to compute the trajectory on-line. In this paper we support the idea that to produce significant advancements in the field of robotics it is important to compare different approaches not only at the theoretical level but also at the implementation level. For this reason we test our software on the iCub platform and compare its performance against other available solutions.},
  keywords={Joints;Trajectory;Robots;Aerospace electronics;Coherence;Kinematics;Software},
  doi={10.1109/IROS.2010.5650851},
  ISSN={2153-0866},
  month={Oct},}@INPROCEEDINGS{10521950,
  author={Meng, Brandon H. and Arachchige, Dimuthu D. K. and Godage, Isuru S. and Kanj, Iyad},
  booktitle={2024 IEEE 7th International Conference on Soft Robotics (RoboSoft)}, 
  title={Path Planning for Continuum Arms in Dynamic Environments}, 
  year={2024},
  volume={},
  number={},
  pages={900-905},
  abstract={Multisection continuum arms are bio-inspired manipulators that combine compliance, payload, dexterity, and safety to serve as co-robots in human-robot collaborative domains. Their hyper redundancy and complex kinematics, however, pose many challenges when performing path planning, especially in dynamic environments. In this paper, we present a W-Space based Rapidly Exploring Random Trees * path planner for multisection continuum arm robots in dynamic environments. The proposed planner improves the existing state-of-art planners in terms of computation time and the success rate, while removing the need for offline computation. On average, the computation time of our approach is below 2 seconds, and its average success rate is around 70 %. The computation time of the proposed planner significantly improves that of the state-of-the-art planner by roughly a factor of 20, making the former suitable for real-time applications. Moreover, for application domains where the obstacle motion is not very predictable (e.g., human obstacles), the proposed planner significantly improves the success rate of state-of-the-art planners by nearly 50 %. Lastly, we demonstrate the feasibility of several generated trajectories by replicating the motion on a physical prototype arm.},
  keywords={Adaptation models;Dynamics;Redundancy;Prototypes;Soft robotics;Real-time systems;Trajectory},
  doi={10.1109/RoboSoft60065.2024.10521950},
  ISSN={2769-4534},
  month={April},}@INPROCEEDINGS{10448556,
  author={Shivaanivarsha, N and Adithya, B Sai and Aadithya, B Shree Bala and Darshan, R and Dhanush, R},
  booktitle={2023 Intelligent Computing and Control for Engineering and Business Systems (ICCEBS)}, 
  title={A Robust and Safe Artificial Intelligence Based Robot Navigation for Smart Buildings}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent days Chabot's are used by examining their key characteristics, applications, and implications and its importance. The fundamental features of Chabot, which include natural language processing, machine learning, and artificial intelligence. These technologies enable Chabot's to understand and respond to human input, simulating meaningful conversations. Proposed system present future directions and challenges in the field of Chabot and robots. In conclusion, Chabot robots represent a transformative technology that enables human-like conversations, with wide-ranging applications and implications. While the field is rapidly evolving, further research, innovation, and ethical considerations are essential to fully harness the potential of Chabot robots and ensure their responsible and beneficial integration into society.},
  keywords={Technological innovation;Smart buildings;Navigation;Oral communication;Machine learning;Medical services;Chatbots;Rocker Bogie;Chat Bot;AI;Robot Navigation},
  doi={10.1109/ICCEBS58601.2023.10448556},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9495963,
  author={Polic, Marsela and Ivanovic, Antun and Maric, Bruno and Arbanas, Barbara and Tabak, Jelena and Orsag, Matko},
  booktitle={2021 16th International Conference on Telecommunications (ConTEL)}, 
  title={Structured Ecological Cultivation with Autonomous Robots in Indoor Agriculture}, 
  year={2021},
  volume={},
  number={},
  pages={189-195},
  abstract={A robotic system for indoor organic farming is presented in this paper. The system consists of heterogeneous robot agents with specific abilities, able to execute certain tasks only when working together, namely, an unmanned aerial robot (UAV), unmanned ground robots (UGV), and a compliant multi degree of freedom dual arm manipulator. The compliant manipulator, responsible for the delicate task of plant treatment, is developed within the Soft robotics paradigm. Using the Soft robotics principles, a dexterous human like motion can be achieved through the simultaneous deployment of Soft robot body parts, compliant control, and tactile sensing capabilities of the manipulator. Testing the robots on the described challenging application represents an interesting research opportunity in the rapidly expanding research field of Soft robotics. Coupled with high level mission planning and safe human robot collaboration, this framework has the capacity to change and automate traditional farming techniques.},
  keywords={Soft robotics;Robot sensing systems;Manipulators;Agriculture;Unmanned aerial vehicles;Sensors;Planning;Multi agent system;soft robotics;AI;agriculture},
  doi={10.23919/ConTEL52528.2021.9495963},
  ISSN={},
  month={June},}@INPROCEEDINGS{9035030,
  author={Pavlichenko, Dmytro and Rodriguez, Diego and Lenz, Christian and Schwarz, Max and Behnke, Sven},
  booktitle={2019 IEEE-RAS 19th International Conference on Humanoid Robots (Humanoids)}, 
  title={Autonomous Bimanual Functional Regrasping of Novel Object Class Instances}, 
  year={2019},
  volume={},
  number={},
  pages={351-358},
  abstract={In human-made scenarios, robots need to be able to fully operate objects in their surroundings, i.e., objects are required to be functionally grasped rather than only picked. This imposes very strict constraints on the object pose such that a direct grasp can be performed. Inspired by the anthropomorphic nature of humanoid robots, we propose an approach that first grasps an object with one hand, obtaining full control over its pose, and performs the functional grasp with the second hand subsequently. Thus, we develop a fully autonomous pipeline for dual-arm functional regrasping of novel familiar objects, i.e., objects never seen before that belong to a known object category, e.g., spray bottles. This process involves semantic segmentation, object pose estimation, non-rigid mesh registration, grasp sampling, handover pose generation and in-hand pose refinement. The latter is used to compensate for the unpredictable object movement during the first grasp. The approach is applied to a human-like upper body. To the best knowledge of the authors, this is the first system that exhibits autonomous bimanual functional regrasping capabilities. We demonstrate that our system yields reliable success rates and can be applied on-line to real-world tasks using only one off-the-shelf RGB-D sensor.},
  keywords={Pose estimation;Robot sensing systems;Handover;Pipelines;Grasping},
  doi={10.1109/Humanoids43949.2019.9035030},
  ISSN={2164-0580},
  month={Oct},}@INPROCEEDINGS{5756946,
  author={Zanchettin, Andrea Maria and Rocco, Paolo and Bascetta, Luca and Symeonidis, Ioannis and Peldschus, Steffen},
  booktitle={ISR 2010 (41st International Symposium on Robotics) and ROBOTIK 2010 (6th German Conference on Robotics)}, 
  title={Kinematic motion analysis of the human arm during a manipulation task}, 
  year={2010},
  volume={},
  number={},
  pages={1-6},
  abstract={Research in the field of human kinematic analysis has gained interest in recent years and has fostered new ideas and expectations. Next generations of manipulators are expected to resemble a human-like behaviour at kinematic level, in order to avoid any unease or discomfort (like fear or shock) to the nearby humans. Robot manufactures are in fact already putting on the market kinematically redundant manipulators that guarantee high levels of dexterity and a more flexible motion planning. In this paper, a kinematic experimental approach to study the motion of the human arm will be presented. In particular, the proposed scenario will be used to study how humans exploit the kinematic redundancy of their arm, for a future use in a robotic controller.},
  keywords={Humans;Kinematics;Joints;Wrist;Elbow;Manipulators},
  doi={},
  ISSN={},
  month={June},}@ARTICLE{6392463,
  author={Frisoli, Antonio and Loconsole, Claudio and Leonardis, Daniele and Banno, Filippo and Barsotti, Michele and Chisari, Carmelo and Bergamasco, Massimo},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 
  title={A New Gaze-BCI-Driven Control of an Upper Limb Exoskeleton for Rehabilitation in Real-World Tasks}, 
  year={2012},
  volume={42},
  number={6},
  pages={1169-1179},
  abstract={This paper proposes a new multimodal architecture for gaze-independent brain-computer interface (BCI)-driven control of a robotic upper limb exoskeleton for stroke rehabilitation to provide active assistance in the execution of reaching tasks in a real setting scenario. At the level of action plan, the patient's intention is decoded by means of an active vision system, through the combination of a Kinect-based vision system, which can online robustly identify and track 3-D objects, and an eye-tracking system for objects selection. At the level of action generation, a BCI is used to control the patient's intention to move his/her own arm, on the basis of brain activity analyzed during motor imagery. The main kinematic parameters of the reaching movement (i.e., speed, acceleration, and jerk) assisted by the robot are modulated by the output of the BCI classifier so that the robot-assisted movement is performed under a continuous control of patient's brain activity. The system was experimentally evaluated in a group of three healthy volunteers and four chronic stroke patients. Experimental results show that all subjects were able to operate the exoskeleton movement by BCI with a classification error rate of 89.4±5.0% in the robot-assisted condition, with no difference of the performance observed in stroke patients compared with healthy subjects. This indicates the high potential of the proposed gaze-BCI-driven robotic assistance for neurorehabilitation of patients with motor impairments after stroke since the earliest phase of recovery.},
  keywords={Robots;Human-robot interaction;User interfaces;Man machine systems;Exoskeleton;Patient rehabilitation;Multimodal sensors;Brain models;Object recognition;Tracking;Machine vision;Brain–computer interface (BCI);exoskeleton;eye tracking;human-like movement;human–robot interaction;neurorehabilitation},
  doi={10.1109/TSMCC.2012.2226444},
  ISSN={1558-2442},
  month={Nov},}@INPROCEEDINGS{7294226,
  author={Chu, Xianghua and Fleischer, Heidi and Roddelkopf, Thomas and Stoll, Norbert and Klos, Michael and Thurow, Kerstin},
  booktitle={2015 IEEE International Conference on Automation Science and Engineering (CASE)}, 
  title={A LC-MS integration approach in life science automation: Hardware integration and software integration}, 
  year={2015},
  volume={},
  number={},
  pages={979-984},
  abstract={Robots are widely used in life science automation due to their advantages, such as reducing manpower, ensuring uniformity and eliminating contaminations. Single-arm robots, with multiple degrees of freedom, have been used to transport labware, e.g. transporting microplates. Nowadays dual-arm robots draw much attraction due to their flexibility, but their applications in life sciences are still limited. In this case, a platform based on a Yaskawa CSDA10F dual-arm robot has been realized in the Center for Life Science Automation (celisca), Germany. In this platform, the robot is not only used to prepare samples by using labware, including pipettes, glass vials, microplates, thermoshaker and so on, in a human-like way, but also employed to integrate a liquid chromatography-mass spectrometry instrument (LC-MS) to the platform for sample analysis purposes. In order to enhance the degree of automation, the analysis process needs to be started automatically after the prepared samples are fed to the LC-MS. This was achieved by integrating the software system of the LC-MS to the SAMI Workstation EX Software system (SAMI EX, Beckman Coulter Inc.), which is user friendly and used for process scheduling. The integration was realized based on the user interface and eXtensible Markup Language (XML). The LC-MS can be controlled by imitating the signals of mouse events and keystrokes to the user interface (such as starting or stopping analysis process); XML data is used for detailed control information.},
  keywords={Robots;Software;Automation;User interfaces;XML;Mice;Life sciences},
  doi={10.1109/CoASE.2015.7294226},
  ISSN={2161-8089},
  month={Aug},}@ARTICLE{9254120,
  author={Gim, Suhyeon and Lee, Sukhan and Adouane, Lounis},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Safe and Efficient Lane Change Maneuver for Obstacle Avoidance Inspired From Human Driving Pattern}, 
  year={2022},
  volume={23},
  number={3},
  pages={2155-2169},
  abstract={One of the most important and fundamental topics in autonomous navigated vehicle research is the lane change maneuver for obstacle avoidance or overtaking maneuver. In the literature, the lane change maneuver path for car-like vehicles has widely been generated with geometrically smooth segments by solving boundary conditions under given constraints. This paper proposes a new method of continuous curvature path generation for the issue of lane change maneuver for obstacle avoidance while solving the clothoids composition problem using an efficient algorithmic procedure. Conventional approaches resorting to mathematical or engineering optimization without considering human-side activity and response may fail to deliver driving performance that is favorable to humans. The novelty of the proposed method lies in its adoption of a human driving pattern, which is non-symmetric and composed of two different modes of avoidance and recovery during the maneuver, and utilizes the property given by an appropriate iterative algorithm which takes into account all the constraints in order to solve the problem. As compared to conventional methods, the proposed method not only provides overall safety for obstacle avoidance, but also exhibits efficiency of increased comfort and human like steering motion during the lane change maneuver. The proposed path planning method is compared to other methods in order to validate its efficiency for safe and smooth obstacle avoidance maneuver.},
  keywords={Collision avoidance;Vehicles;Roads;Boundary conditions;Turning;Wheels;Trajectory;Continuous curvature path;human driving pattern;clothoid;lane change maneuver;obstacle avoidance, passenger comfort},
  doi={10.1109/TITS.2020.3034099},
  ISSN={1558-0016},
  month={March},}@INPROCEEDINGS{9551480,
  author={Yang, Yufan and Chen, Weiming and Zhou, Lingxiang and Zheng, Bote and Xiao, Wei and Huang, Yanwei and Sun, Zhenglong},
  booktitle={2021 IEEE 17th International Conference on Automation Science and Engineering (CASE)}, 
  title={A Hybrid Control Framework Teaching Robot to Write Chinese Characters: from Image to Handwriting}, 
  year={2021},
  volume={},
  number={},
  pages={1161-1166},
  abstract={Teaching a robot to learn calligraphy writing has been an interesting and challenging topic for robot learning. Ideally, to achieve human-like behavior, a robot can imitate any character fonts out of image inputs only. In the past decades, many works have been done in different kinds of special calligraphy robots design and learning by demonstration. Recently, advanced learning algorithms such as reinforcement learning have also been used with a significant sacrifice in data collection and computational complexity. In this paper, we present a simple and compact hybrid learning approach, by combining offline learning in simulator and online motion planing. In our approach, we simplify the writing trajectory generation to an optimization problem considering the width of the stroke as a function of height (z-axis) only. Based on the skeleton from each extracted stroke, Dynamic programming and Gaussian process models are used to solve the widths at each sampling point and to convert into a smooth trajectory. In such manner, a robot can learn to write any Chinese character directly from an image input within half a minute.},
  keywords={Planing;Education;Reinforcement learning;Gaussian processes;Writing;Skeleton;Robot learning},
  doi={10.1109/CASE49439.2021.9551480},
  ISSN={2161-8089},
  month={Aug},}@ARTICLE{9536385,
  author={Mullen, James F. and Mosier, Josh and Chakrabarti, Sounak and Chen, Anqi and White, Tyler and Losey, Dylan P.},
  journal={IEEE Robotics and Automation Letters}, 
  title={Communicating Inferred Goals With Passive Augmented Reality and Active Haptic Feedback}, 
  year={2021},
  volume={6},
  number={4},
  pages={8522-8529},
  abstract={Robots learn as they interact with humans. Consider a human teleoperating an assistive robot arm: as the human guides and corrects the arm's motion, the robot gathers information about the human's desired task. But how does the human know what their robot has inferred? Today's approaches often focus on conveying intent: for instance, using legible motions or gestures to indicate what the robot is planning. However, closing the loop on robot inference requires more than just revealing the robot's current policy: the robot should also display the alternatives it thinks are likely, and prompt the human teacher when additional guidance is necessary. In this letter we propose a multimodal approach for communicating robot inference that combines both passive and active feedback. Specifically, we leverage information-rich augmented reality to passively visualize what the robot has inferred, and attention-grabbing haptic wristbands to actively prompt and direct the human's teaching. We apply our system to shared autonomy tasks where the robot must infer the human's goal in real-time. Within this context, we integrate passive and active modalities into a single algorithmic framework that determines when and which type of feedback to provide. Combining both passive and active feedback experimentally outperforms single modality baselines; during an in-person user study, we demonstrate that our integrated approach increases how efficiently humans teach the robot while simultaneously decreasing the amount of time humans spend interacting with the robot. Videos here: https://youtu.be/swq_u4iIP-g},
  keywords={Robots;Haptic interfaces;Augmented reality;Education;Visualization;Task analysis;Manipulators;Haptics and haptic interfaces;virtual reality and interfaces;intention recognition},
  doi={10.1109/LRA.2021.3111055},
  ISSN={2377-3766},
  month={Oct},}@INPROCEEDINGS{10610332,
  author={Luo, Yuxuan and Wu, Zekun and Lian, Zhouhui},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={CalliRewrite: Recovering Handwriting Behaviors from Calligraphy Images without Supervision}, 
  year={2024},
  volume={},
  number={},
  pages={8671-8678},
  abstract={Human-like planning skills and dexterous manipulation have long posed challenges in the fields of robotics and artificial intelligence (AI). The task of reinterpreting calligraphy presents a formidable challenge, as it involves the decomposition of strokes and dexterous utensil control. Previous efforts have primarily focused on supervised learning of a single instrument, limiting the performance of robots in the realm of cross-domain text replication. To address these challenges, we propose CalliRewrite: a coarse-to-fine approach for robot arms to discover and recover plausible writing orders from diverse calligraphy images without requiring labeled demonstrations. Our model achieves fine-grained control of various writing utensils. Specifically, an unsupervised image-to-sequence model decomposes a given calligraphy glyph to obtain a coarse stroke sequence. Using an RL algorithm, a simulated brush is fine-tuned to generate stylized trajectories for robotic arm control. Evaluation in simulation and physical robot scenarios reveals that our method successfully replicates unseen fonts and styles while achieving integrity in unknown characters. To access our code and supplementary materials, please visit our project page: https://luoprojectpage.github.io/callirewrite/.},
  keywords={Training;Limiting;Instruments;Supervised learning;Writing;Manipulators;Trajectory},
  doi={10.1109/ICRA57147.2024.10610332},
  ISSN={},
  month={May},}@INPROCEEDINGS{9981196,
  author={Stavridis, Sotiris and Papageorgiou, Dimitrios and Doulgeri, Zoe},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Kinesthetic teaching of bi-manual tasks with known relative constraints}, 
  year={2022},
  volume={},
  number={},
  pages={11796-11801},
  abstract={Kinesthetic teaching allows the direct skill transfer from the human to the robot and has been widely used to teach single arm tasks intuitively. In the bi-manual case, simultaneously moving both end-effectors is challenging due to the high physical and cognitive load imposed to the user. Thus, previous works on bi-manual task teaching resort to less intuitive methods by teaching each arm separately. This in turn requires motion synthesis and synchronization before execution. In this work, we leverage knowledge from the relative task space to facilitate a kinesthetic demonstration by guiding both end-effectors which is more human-like and intuitive way for performing bi-manual tasks. Our method utilizes the notion of virtual fixtures and inertia minimization in the null space of the task. The controller is experimentally validated in a bi-manual task which involves the drawing of a preset line on a workpiece utilizing two KUKA IIWA7 R800 robots. Results from ten participants were compared with a gravity compensation scheme demonstrating improved performance.},
  keywords={Measurement;Geometry;Education;Null space;Minimization;End effectors;Synchronization},
  doi={10.1109/IROS47612.2022.9981196},
  ISSN={2153-0866},
  month={Oct},}
